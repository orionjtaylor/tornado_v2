{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package import cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull all storm events (2008-2018)\n",
    "# Source URL: https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/\n",
    "\n",
    "storms = pd.DataFrame()\n",
    "years = ['2008_c20180718', '2009_c20180718', '2010_c20170726', \n",
    "         '2011_c20180718', '2012_c20170519', '2013_c20170519', \n",
    "         '2014_c20180718', '2015_c20180525', '2016_c20180718',\n",
    "         '2017_c20181017', '2018_c20181116']\n",
    "\n",
    "for year in years:\n",
    "    storms = storms.append(pd.read_csv('/users/Orion/Desktop/tornado-data/StormEvents_details-ftp_v1.0_d'\n",
    "                                       +str(year)+'.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SOUTH CAROLINA', 'TEXAS', 'WISCONSIN', 'LOUISIANA', 'MISSOURI',\n",
       "       'ILLINOIS', 'MINNESOTA', 'MISSISSIPPI', 'FLORIDA',\n",
       "       'NORTH CAROLINA', 'GEORGIA', 'ALABAMA', 'SOUTH DAKOTA', 'KANSAS',\n",
       "       'IOWA', 'VIRGINIA', 'COLORADO', 'TENNESSEE', 'OKLAHOMA',\n",
       "       'NEBRASKA', 'WEST VIRGINIA', 'KENTUCKY', 'MARYLAND', 'ARKANSAS',\n",
       "       'MONTANA', 'IDAHO', 'WYOMING', 'MICHIGAN', 'PENNSYLVANIA', 'OHIO',\n",
       "       'HAWAII', 'NEW MEXICO', 'CALIFORNIA', 'ARIZONA', 'INDIANA',\n",
       "       'WASHINGTON', 'NORTH DAKOTA', 'NEW YORK', 'NEW HAMPSHIRE',\n",
       "       'MASSACHUSETTS', 'VERMONT', 'RHODE ISLAND', 'OREGON', 'MAINE',\n",
       "       'UTAH', 'CONNECTICUT', 'NEVADA', 'NEW JERSEY', 'PUERTO RICO',\n",
       "       'DELAWARE', 'DISTRICT OF COLUMBIA'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out non-tornado events\n",
    "\n",
    "tornadoes = storms.loc[storms['EVENT_TYPE'] == 'Tornado']\n",
    "\n",
    "# Check states where tornadoes have occurred (to help target additional data mining)\n",
    "\n",
    "tornadoes['STATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull income data (2016)\n",
    "# Source URL: https://www.census.gov/data/datasets/2016/demo/saipe/2016-state-and-county.html\n",
    "\n",
    "income = pd.read_csv('/users/Orion/Desktop/tornado-data/Median_Household_Income.csv', header=3)\n",
    "\n",
    "# Clean income data to match 'State FIPS Code' and 'Name' formatting \n",
    "# with tornado 'STATE_FIPS' and 'CZ_NAME' data\n",
    "\n",
    "income['State FIPS Code'] = income['State FIPS Code'].astype(int)\n",
    "income = income[~income['Name'].str.contains(\"County\") == False]\n",
    "income['Name'].replace(regex=True,inplace=True,to_replace=r' County',value=r'')\n",
    "income['Name'] = income['Name'].str.upper()\n",
    "\n",
    "# Isolate 'State FIPS Code' and 'Name' (for data merging), and\n",
    "# pull 'Median Household Income', which is our only column of interest\n",
    "\n",
    "income = income[['State FIPS Code', 'Name', 'Median Household Income']]\n",
    "\n",
    "# Merge income and tornado dataframes on FIPS and county columns (per above)\n",
    "\n",
    "tornadoes_with_income = pd.merge(tornadoes, income, how='left', \n",
    "                                 left_on=['STATE_FIPS','CZ_NAME'], \n",
    "                                 right_on=['State FIPS Code','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull population density data (2010)\n",
    "# Source URL: https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?src=bkmk \n",
    "# Note: URL above wasn't working for Orion -- used .CSV file emailed by Sree\n",
    "\n",
    "density = pd.read_csv('/users/Orion/Desktop/tornado-data/Population_Density.csv', encoding='cp1252', header=1)\n",
    "\n",
    "# Clean density data to match 'Geographic area' and Geographic area.1' formatting \n",
    "# with tornado+income 'STATE' and 'CZ_NAME' data\n",
    "\n",
    "density = density[~density['Geographic area.1'].str.contains(\"County\") == False]\n",
    "density['Geographic area.1'].replace(regex=True,inplace=True,to_replace=r' County',value=r'')\n",
    "density['Geographic area.1'] = density['Geographic area.1'].str.upper()\n",
    "density['Geographic area'].replace(regex=True,inplace=True,to_replace=r'United States - ',value=r'')\n",
    "density['Geographic area'] = [x.split(' -')[0] for x in density['Geographic area']]\n",
    "density['Geographic area'] = density['Geographic area'].str.upper()\n",
    "\n",
    "# Isolate 'Geographic area' and 'Geographic area.1' (for data merging), and\n",
    "# pull 'Density per square mile of land area - Population' and\n",
    "# 'Density per square mile of landa area - Housing units', \n",
    "# which is the only column of interest\n",
    "\n",
    "density = density[['Geographic area', 'Geographic area.1', 'Population', 'Housing units', \n",
    "                   'Area in square miles - Total area', 'Area in square miles - Land area',\n",
    "                   'Density per square mile of land area - Population', \n",
    "                   'Density per square mile of land area - Housing units']]\n",
    "\n",
    "\n",
    "# Merge density and tornado+income dataframes on state and county columns (per above)\n",
    "\n",
    "tornadoes_with_income_with_density = pd.merge(tornadoes_with_income, density, how='left',\n",
    "                                              left_on=['STATE','CZ_NAME'], \n",
    "                                              right_on=['Geographic area','Geographic area.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting merged dataset to .CSV for use in Data Cleaning notebook\n",
    "\n",
    "tornadoes_with_income_with_density.to_csv('Merged-Tornadoes.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
